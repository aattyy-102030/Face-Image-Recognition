{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.** **各種インポート**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt #グラフ表示など用ライブラリ\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator #軸の表示設定用\n",
    "# ノートブックでmatplotを使う時にはinline指定をした方が良い\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path # pathの扱いが便利になるライブラリ\n",
    "\n",
    "from tqdm.notebook import tqdm # プログレスバー表示用\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch #PyTorch\n",
    "import torch.nn as nn #PyTorchのニューラルネットワークに関するもの\n",
    "import torch.optim as optim #最適化関数利用のため\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision # PyTorchの画像に関するものをまとめたもの\n",
    "import torchvision.models\n",
    "from torchvision import transforms #データセットの画像加工用\n",
    "from torchvision.datasets import ImageFolder #ImageFolderクラス利用のため\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.** **各種設定**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title #Hyper Parameters\n",
    "n_epochs =  20#@param {type:\"integer\"}\n",
    "batchsize =  8#@param {type:\"integer\"}\n",
    "learning_rate = 0.001 #@param {type:\"raw\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title #Input/Output\n",
    "#@markdown ### trainデータセットのパス:\n",
    "#TRAIN_DATA_PATH = \"/content/ManWoman-dataset/dataset/Train\"#@param{type:\"string\"}\n",
    "TRAIN_DATA_PATH = \"C:/Users/yutam/Desktop/Data_analysis/FaceDetection/ManWoman-dataset/Train\"\n",
    "\n",
    "#@markdown ### testデータセットのパス:\n",
    "#TEST_DATA_PATH = \"/content/ManWoman-dataset/dataset/Test\"#@param{type:\"string\"}\n",
    "TEST_DATA_PATH =\"C:/Users/yutam/Desktop/Data_analysis/FaceDetection/Face_dateset/final_files\"\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown ### 1エポックごとに何回ログをprintするか:\n",
    "PRINT_COUNT_PER_EPOCH =   10#@param{type:\"integer\"}\n",
    "\n",
    "#@markdown ### 出力結果を保存する基本的なパス:\n",
    "#BASE_OUT_PATH = '/content/drive/MyDrive/grad-research/' #@param{type:\"string\"}\n",
    "BASE_OUT_PATH ='C:/Users/yutam/Desktop/Data_analysis/FaceDetection/Output_Models'\n",
    "\n",
    "#BASE_OUT_PATH = '/content/drive/Shareddrives/HOSONOLAB_2021/20220126_データセット/'\n",
    "#@markdown ### 学習したモデルを保存する名前:\n",
    "MODEL_OUT_NAME = 'model.pth' #@param{type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3.** **前処理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #データセットの画像加工用 Transform を作成\n",
    "# transform = {\n",
    "#     'Train':transforms.Compose(\n",
    "#     [transforms.Resize((224,224)), # 画像サイズを一定にする\n",
    "#      transforms.ToTensor()  # NNで計算しやすい様に画像を変換\n",
    "#      ]),\n",
    "#      'Test':transforms.Compose(\n",
    "#     [transforms.Resize((224,224)), # 画像サイズを一定にする\n",
    "#      transforms.ToTensor()  # NNで計算しやすい様に画像を変換\n",
    "#      ])\n",
    "# }\n",
    "#データセットの画像加工用 Transform を作成\n",
    "transform = {\n",
    "    'Train':transforms.Compose(\n",
    "    [transforms.Resize(226), # 画像サイズを一定にする\n",
    "     transforms.CenterCrop(224),\n",
    "     transforms.ToTensor()  # NNで計算しやすい様に画像を変換\n",
    "     ]),\n",
    "     'Test':transforms.Compose(\n",
    "    [transforms.Resize(226), # 画像サイズを一定にする\n",
    "     transforms.CenterCrop(224),\n",
    "     transforms.ToTensor()  # NNで計算しやすい様に画像を変換\n",
    "     ])\n",
    "}\n",
    "\n",
    "\n",
    "# Dataset を作成\n",
    "train_dataset = ImageFolder(TRAIN_DATA_PATH, transform['Train'])\n",
    "print(\"train dataset:/n\",train_dataset,\"/n\")\n",
    "\n",
    "datapoints = len(train_dataset)\n",
    "\n",
    "print(\"train dateset length:/n\",datapoints,\"/n\")\n",
    "print(\"train dataset class to idx:/n\",train_dataset.class_to_idx,\"/n\")\n",
    "\n",
    "# Dataloader を作成\n",
    "# 学習データはエポックごとに各バッチの傾向が変わる（学習の傾向が変わる）ようにshuffleする\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size = batchsize,\n",
    "                                          shuffle=True, num_workers = 0)\n",
    "print(\"train loader:/n\",trainloader,\"/n\")\n",
    "\n",
    "# classラベルをデータセットから読み取る\n",
    "classes = [key for key in  train_dataset.class_to_idx]\n",
    "print(\"classes:/n\",classes,\"/n\") \n",
    "\n",
    "#gpuが使える場合はgpu、そうでない場合はcpuをデバイスに指定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(\"use device:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4.** **学習**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#インスタンス生成\n",
    "#model = MyModel()\n",
    "#model = VGG(n_classes = 2)\n",
    "#model = torchvision.models.densenet121()\n",
    "#model = torchvision.models.efficientnet_b7(pretrained = True, num_classes = 2)\n",
    "\n",
    "model = torchvision.models.efficientnet_b7(pretrained = True) # efficientnet_b7を使用\n",
    "#print(\"model:/n\",model,\"/n\")\n",
    "model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(2560, 2),\n",
    "        )\n",
    "\n",
    "#model.classifier = nn.Linear(2208,2)\n",
    "\n",
    "print(\"model:/n\",model,\"/n\")\n",
    "# 学習モードに切り替える\n",
    "model.train()\n",
    "# モデルをdeviceに送る。CPUで動かしたい時はやらなくても良い。\n",
    "model.to(device) \n",
    "#optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9) #最適化関数\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate,betas=(0.9,0.999)) #最適化関数にはAdamを使用\n",
    "print(\"optimizer:/n\",optimizer,\"/n\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #損失関数-CrossEntropyLoss\n",
    "print(\"criterion:/n\",criterion,\"/n\")\n",
    "\n",
    "# 各エポックで最後にprintした値をグラフ表示用に格納しておくためのもの\n",
    "results_train = {'loss': [],'accuracy': []}\n",
    "\n",
    "# 1エポックごとの反復回数（iteration）\n",
    "iteration = datapoints / batchsize\n",
    "# 何iterationごとにprintするか\n",
    "print_iteration = iteration // PRINT_COUNT_PER_EPOCH\n",
    "\n",
    "print('[epoch, iteration]')\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "  #list for loss and accuracy\n",
    "\n",
    "  running_loss = 0.0\n",
    "  running_accuracy = 0.0\n",
    "  \n",
    "  # 新規エポックごとにリストに要素追加\n",
    "  results_train['loss'].append(running_loss)\n",
    "  results_train['accuracy'].append(running_accuracy)\n",
    "\n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "    images, labels = data\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # forwardを実行\n",
    "    # 特殊なメソッドなのでmodel.forward()のように書かなくてもmodel()で実行されるようになっている\n",
    "    outputs = model(images)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # calculate print loss and accuracy\n",
    "    # lossの加算\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    # outputsの各バッチで何番目のクラスの確率が最大かをpredictedに格納\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    # predictedとlabelsが一致する個数が予測に正解している数correct\n",
    "    correct = (predicted == labels).sum()\n",
    "    # batchsizeで割ることで精度にし、%にする\n",
    "    accuracy = 100 * correct / batchsize\n",
    "    # accuracyの加算\n",
    "    running_accuracy += accuracy.item()\n",
    "    # print_iterationごとのprint\n",
    "    if i % print_iteration == print_iteration - 1:\n",
    "        # 加算したlossとaccuracyを反復数で割る\n",
    "        # 一番最後のprintした値で常に上書きすれば、各epohで最後にprintした値が取得できる\n",
    "        results_train['loss'][epoch] = running_loss / print_iteration\n",
    "        results_train['accuracy'][epoch] = running_accuracy / print_iteration\n",
    "        \n",
    "        print('[%5d, %9d]  loss: %.3f,  accuracy: %.3f' %\n",
    "              (epoch + 1, i + 1, results_train['loss'][epoch],results_train['accuracy'][epoch] ))\n",
    "        \n",
    "        # print iteration毎に変数初期化\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "\n",
    "#モデルの保存\n",
    "\n",
    "#torch.save(model.state_dict(),'model.pth')\n",
    "torch.save(model.state_dict(), BASE_OUT_PATH + MODEL_OUT_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5.** **結果の表示**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 台紙を作成\n",
    "# facecolorはグラフ全体の背景色を設定\n",
    "# dpiで解像度が変わる\n",
    "fig = plt.figure(figsize=(6.4, 4.8), dpi=200, facecolor='w')\n",
    "\n",
    "# 上下に2つのグラフを用意\n",
    "# ylim=(0, 100)のように引数を指定すれば表示範囲が0～100になる\n",
    "# 見やすい範囲については各自で考える\n",
    "axT = fig.add_subplot(211,xlabel='epoch',ylabel='loss')#2行1列の1番目\n",
    "axB = fig.add_subplot(212,xlabel='epoch',ylabel='accuracy')#2行1列の2番目\n",
    "\n",
    "# x軸の要素は、今回epochなので指定しなくても良いが念のため\n",
    "epochs = range(n_epochs)\n",
    "\n",
    "# epochは整数なので整数表示のためのオプション\n",
    "# この行を実行しないとx軸が実数表示になるはず\n",
    "axT.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "axB.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# プロット\n",
    "axT.plot(epochs, results_train['loss'])\n",
    "axB.plot(epochs, results_train['accuracy'])\n",
    "\n",
    "# 軸ラベルと図が被ることを防止\n",
    "fig.tight_layout()\n",
    "# 画像として保存\n",
    "fig.savefig(BASE_OUT_PATH + 'loss_acc.png', facecolor=fig.get_facecolor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6.** **テスト**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### テストに使用する学習済みモデルを読み込むパス:\n",
    "#MODEL_LOAD_PATH =  '/content/drive/My Drive/grad-research/model.pth' #@param{type:\"string\"}\n",
    "MODEL_LOAD_PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder(TEST_DATA_PATH, transform['Test'])\n",
    "print(\"test dataset class to idx:/n\",test_dataset.class_to_idx,\"/n\")\n",
    "test_samples = len(test_dataset)\n",
    "print(\"test samples:/n\",test_samples,\"/n\")\n",
    "\n",
    "# classラベルをデータセットから読み取る\n",
    "classes = [key for key in  test_dataset.class_to_idx]\n",
    "print(\"classes:/n\",classes,\"/n\") \n",
    "\n",
    "test_batchsize = 5\n",
    "# テストデータは全部のデータに同じことをするだけなので普通はsuffleしない\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batchsize,\n",
    "                                         shuffle=False, num_workers = 2)\n",
    "print(\"test loader:/n\",testloader,\"/n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
